import pdfplumber
import json
import re

def clean_footnotes(text):
    """–£–¥–∞–ª—è–µ—Ç —Å–Ω–æ—Å–∫–∏ (—Ü–∏—Ñ—Ä—ã –≤ –≤–µ—Ä—Ö–Ω–µ–º –∏–Ω–¥–µ–∫—Å–µ)"""
    # –£–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ —Å–Ω–æ—Å–æ–∫ —Ç–∏–ø–∞ ¬≤‚Åµ, ¬≤‚Å∂
    text = re.sub(r'[\u2070-\u209F]+.*?(?=\n|$)', '', text, flags=re.DOTALL)
    return text

def parse_muslim_pdf(pdf_path, output_path):
    hadiths = []
    current_book = None
    current_chapter = None
    
    with pdfplumber.open(pdf_path) as pdf:
        print(f"üìÑ –í—Å–µ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {len(pdf.pages)}")
        
        full_text = ""
        for i, page in enumerate(pdf.pages):
            print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {i+1}/{len(pdf.pages)}...", end='\r')
            full_text += page.extract_text() + "\n"
        
        print(f"\n‚úÖ –¢–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á—ë–Ω ({len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        # –£–¥–∞–ª—è–µ–º —Å–Ω–æ—Å–∫–∏
        full_text = clean_footnotes(full_text)
        
        lines = full_text.split('\n')
        
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–Ω–∏–≥—É
            book_match = re.match(r'^(\d+)\.\s*–ö–ù–ò–ì–ê\s+(.+)$', line, re.IGNORECASE)
            if book_match:
                current_book = f"{book_match.group(1)}. {book_match.group(2)}"
                print(f"\nüìö –ö–Ω–∏–≥–∞: {current_book}")
                i += 1
                continue
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–ª–∞–≤—É
            chapter_match = re.match(r'^–ì–ª–∞–≤–∞\s+(\d+)\.(.+)$', line, re.IGNORECASE)
            if chapter_match:
                current_chapter = f"–ì–ª–∞–≤–∞ {chapter_match.group(1)}.{chapter_match.group(2)}"
                i += 1
                continue
            
            # –ò—â–µ–º –Ω–æ–º–µ—Ä —Ö–∞–¥–∏—Å–∞ (–ø—Ä–æ—Å—Ç–æ —Ü–∏—Ñ—Ä–∞ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏)
            hadith_match = re.match(r'^(\d+)\s*$', line)
            if hadith_match:
                hadith_id = int(hadith_match.group(1))
                
                # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç —Ö–∞–¥–∏—Å–∞ (–¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –Ω–æ–º–µ—Ä–∞ –∏–ª–∏ –∫–æ–Ω—Ü–∞)
                hadith_text = []
                i += 1
                
                while i < len(lines):
                    next_line = lines[i].strip()
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –Ω–∞—á–∞–ª—Å—è –ª–∏ –Ω–æ–≤—ã–π —Ö–∞–¥–∏—Å/–∫–Ω–∏–≥–∞/–≥–ª–∞–≤–∞
                    if (re.match(r'^(\d+)\s*$', next_line) or 
                        re.match(r'^\d+\.\s*–ö–ù–ò–ì–ê', next_line, re.IGNORECASE) or
                        re.match(r'^–ì–ª–∞–≤–∞\s+\d+', next_line, re.IGNORECASE)):
                        break
                    
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
                    if next_line and not next_line.startswith('–¥–∏–ª'):
                        hadith_text.append(next_line)
                    
                    i += 1
                
                if hadith_text:
                    hadiths.append({
                        'id': hadith_id,
                        'text': ' '.join(hadith_text),
                        'book': current_book,
                        'chapter': current_chapter
                    })
                    
                    if hadith_id % 100 == 0:
                        print(f"üìñ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ö–∞–¥–∏—Å–æ–≤: {len(hadiths)} (–ø–æ—Å–ª–µ–¥–Ω–∏–π ID: {hadith_id})")
                
                continue
            
            i += 1
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump({
            'total': len(hadiths),
            'hadiths': hadiths
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nüéâ –ì–û–¢–û–í–û!")
    print(f"üìä –í—Å–µ–≥–æ —Ö–∞–¥–∏—Å–æ–≤: {len(hadiths)}")
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_path}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    ids = sorted([h['id'] for h in hadiths])
    min_id = min(ids)
    max_id = max(ids)
    total_found = len(ids)
    expected_range = max_id - min_id + 1
    gaps_count = expected_range - total_found
    coverage = (total_found / expected_range) * 100
    
    print(f"üìà –î–∏–∞–ø–∞–∑–æ–Ω ID: {min_id} - {max_id}")
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ —Ö–∞–¥–∏—Å–æ–≤: {total_found} –∏–∑ {expected_range} –≤–æ–∑–º–æ–∂–Ω—ã—Ö ({coverage:.1f}% –ø–æ–∫—Ä—ã—Ç–∏–µ)")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ ID –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
    if gaps_count > 0:
        gaps_sample = []
        count = 0
        for expected_id in range(min_id, max_id + 1):
            if expected_id not in ids:
                gaps_sample.append(expected_id)
                count += 1
                if count >= 30:
                    break
        
        print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ ID (–ø–µ—Ä–≤—ã–µ 30): {gaps_sample}...")
        print(f"   –í—Å–µ–≥–æ –ø—Ä–æ–ø—É—â–µ–Ω–æ: {gaps_count} ID")
        print(f"‚ÑπÔ∏è  –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –≠—Ç–æ —Å–æ–∫—Ä–∞—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è (–ú—É—Ö—Ç–∞—Å–∞—Ä), –ø—Ä–æ–ø—É—Å–∫–∏ - —ç—Ç–æ –Ω–æ—Ä–º–∞!")
    else:
        print("‚úÖ –í—Å–µ ID –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python parse_muslim_pdf.py <–ø—É—Ç—å_–∫_pdf>")
        print("–ü—Ä–∏–º–µ—Ä: python parse_muslim_pdf.py data/muslim.pdf")
        sys.exit(1)
    
    pdf_path = sys.argv[1]
    output_path = pdf_path.replace('.pdf', '_parsed.json')
    
    parse_muslim_pdf(pdf_path, output_path)